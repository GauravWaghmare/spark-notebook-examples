{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9be8bbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gauravwaghmare/Documents/Personal/spark-notebook-examples/test-notebook\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6290ad6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMMAND_MODE=unix2003\n",
      "GEMINI_API_KEY=AIzaSyBPv1k2EOhuVfNWmNiqrHDkksHmV6EA8Z0\n",
      "GVM_PATH_BACKUP=/Users/gauravwaghmare/.gvm/bin:/Users/gauravwaghmare/.nvm/versions/node/v20.12.2/bin:/Users/gauravwaghmare/.local/bin:/opt/homebrew/Cellar/openjdk@17/17.0.15/libexec/openjdk.jdk/Contents/Home/bin:/Library/Frameworks/Python.framework/Versions/3.8/bin:/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/System/Cryptexes/App/usr/bin:/usr/bin:/bin:/usr/sbin:/sbin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/local/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/appleinternal/bin:/Library/Apple/usr/bin:/usr/local/go/bin:/Users/gauravwaghmare/.cargo/bin:/Users/gauravwaghmare/Library/Application Support/Coursier/bin\n",
      "GVM_ROOT=/Users/gauravwaghmare/.gvm\n",
      "GVM_VERSION=1.0.22\n",
      "HOME=/Users/gauravwaghmare\n",
      "HOMEBREW_CELLAR=/opt/homebrew/Cellar\n",
      "HOMEBREW_PREFIX=/opt/homebrew\n",
      "HOMEBREW_REPOSITORY=/opt/homebrew\n",
      "INFOPATH=/opt/homebrew/share/info:\n",
      "JAVA_HOME=/opt/homebrew/Cellar/openjdk@17/17.0.15/libexec/openjdk.jdk/Contents/Home\n",
      "LANG=C.UTF-8\n",
      "LESS=-R\n",
      "LOGNAME=gauravwaghmare\n",
      "LSCOLORS=Gxfxcxdxbxegedabagacad\n",
      "LS_COLORS=di=1;36:ln=35:so=32:pi=33:ex=31:bd=34;46:cd=34;43:su=30;41:sg=30;46:tw=30;42:ow=30;43\n",
      "MallocNanoZone=0\n",
      "NVM_BIN=/Users/gauravwaghmare/.nvm/versions/node/v20.12.2/bin\n",
      "NVM_CD_FLAGS=-q\n",
      "NVM_DIR=/Users/gauravwaghmare/.nvm\n",
      "NVM_INC=/Users/gauravwaghmare/.nvm/versions/node/v20.12.2/include/node\n",
      "OLDPWD=/\n",
      "OSLogRateLimit=64\n",
      "PAGER=cat\n",
      "PATH=/Users/gauravwaghmare/Documents/Personal/spark-notebook-examples/.venv/bin:/opt/homebrew/opt/postgresql@17/bin:/opt/homebrew/opt/go@1.23/bin:/Users/gauravwaghmare/google-cloud-sdk/bin:/opt/homebrew/opt/scala@2.13/bin:/Users/gauravwaghmare/.gvm/bin:/Users/gauravwaghmare/.nvm/versions/node/v20.12.2/bin:/Users/gauravwaghmare/.local/bin:/opt/homebrew/Cellar/openjdk@17/17.0.15/libexec/openjdk.jdk/Contents/Home/bin:/Library/Frameworks/Python.framework/Versions/3.8/bin:/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/System/Cryptexes/App/usr/bin:/usr/bin:/bin:/usr/sbin:/sbin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/local/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/appleinternal/bin:/Library/Apple/usr/bin:/usr/local/go/bin:/Users/gauravwaghmare/.cargo/bin:/Users/gauravwaghmare/Library/Application:Support/Coursier/bin:/Users/gauravwaghmare/go/bin\n",
      "PWD=/\n",
      "SHELL=/bin/zsh\n",
      "SHLVL=1\n",
      "SSH_AUTH_SOCK=/private/tmp/com.apple.launchd.UNFJO9g4T4/Listeners\n",
      "TMPDIR=/var/folders/77/yhhzx4_x2c985ts6vqgbx_0r0000gn/T/\n",
      "USER=gauravwaghmare\n",
      "VSCODE_CODE_CACHE_PATH=/Users/gauravwaghmare/Library/Application Support/Code/CachedData/994fd12f8d3a5aa16f17d42c041e5809167e845a\n",
      "VSCODE_CRASH_REPORTER_PROCESS_TYPE=extensionHost\n",
      "VSCODE_CWD=/\n",
      "VSCODE_ESM_ENTRYPOINT=vs/workbench/api/node/extensionHostProcess\n",
      "VSCODE_HANDLES_UNCAUGHT_ERRORS=true\n",
      "VSCODE_IPC_HOOK=/Users/gauravwaghmare/Library/Application Support/Code/1.10-main.sock\n",
      "VSCODE_NLS_CONFIG={\"userLocale\":\"en-gb\",\"osLocale\":\"en-in\",\"resolvedLanguage\":\"en\",\"defaultMessagesFile\":\"/Applications/Visual Studio Code.app/Contents/Resources/app/out/nls.messages.json\",\"locale\":\"en-gb\",\"availableLanguages\":{}}\n",
      "VSCODE_PID=2667\n",
      "XPC_FLAGS=0x0\n",
      "XPC_SERVICE_NAME=0\n",
      "ZSH=/Users/gauravwaghmare/.oh-my-zsh\n",
      "_=/Users/gauravwaghmare/Documents/Personal/spark-notebook-examples/.venv/bin/python\n",
      "__CFBundleIdentifier=com.microsoft.VSCode\n",
      "__CF_USER_TEXT_ENCODING=0x1F5:0x0:0x0\n",
      "ELECTRON_RUN_AS_NODE=1\n",
      "APPLICATION_INSIGHTS_NO_STATSBEAT=true\n",
      "VSCODE_L10N_BUNDLE_LOCATION=\n",
      "APPLICATION_INSIGHTS_NO_DIAGNOSTIC_CHANNEL=1\n",
      "APPLICATIONINSIGHTS_CONFIGURATION_CONTENT={}\n",
      "PYTHONUNBUFFERED=1\n",
      "PYTHONIOENCODING=utf-8\n",
      "VIRTUAL_ENV=/Users/gauravwaghmare/Documents/Personal/spark-notebook-examples/.venv\n",
      "PS1=(.venv) \n",
      "VIRTUAL_ENV_PROMPT=(.venv) \n",
      "PYDEVD_IPYTHON_COMPATIBLE_DEBUGGING=1\n",
      "PYTHON_FROZEN_MODULES=on\n",
      "PYDEVD_USE_FRAME_EVAL=NO\n",
      "TERM=xterm-color\n",
      "CLICOLOR=1\n",
      "FORCE_COLOR=1\n",
      "CLICOLOR_FORCE=1\n",
      "GIT_PAGER=cat\n",
      "MPLBACKEND=module://matplotlib_inline.backend_inline\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for key, value in os.environ.items():\n",
    "    print(f\"{key}={value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615f25e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hello'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhello\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhello\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m hello_world\n\u001b[1;32m      3\u001b[0m hello_world()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'hello'"
     ]
    }
   ],
   "source": [
    "from hello.hello import hello_world\n",
    "\n",
    "hello_world()\n",
    "hello_world()\n",
    "hello_world()\n",
    "hello_world()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc5ff23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "import time\n",
    "import random\n",
    "\n",
    "try:\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"Complex Spark Job\") \\\n",
    "        .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "        .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    print(\"Starting complex Spark job...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Generate a larger dataset (1 million records)\n",
    "    print(\"Step 1: Generating large dataset...\")\n",
    "    large_data = []\n",
    "    for i in range(1000000):\n",
    "        large_data.append((\n",
    "            f\"User_{i % 10000}\",  # 10k unique users\n",
    "            random.randint(18, 80),  # Age\n",
    "            random.choice(['M', 'F']),  # Gender\n",
    "            random.choice(['NY', 'CA', 'TX', 'FL', 'WA']),  # State\n",
    "            random.uniform(1000, 10000),  # Salary\n",
    "            random.choice(['Tech', 'Finance', 'Healthcare', 'Education', 'Retail'])  # Industry\n",
    "        ))\n",
    "    \n",
    "    df = spark.createDataFrame(large_data, [\"UserID\", \"Age\", \"Gender\", \"State\", \"Salary\", \"Industry\"])\n",
    "    df.cache()  # Cache for multiple operations\n",
    "    \n",
    "    print(f\"Created dataset with {df.count():,} records\")\n",
    "\n",
    "    # Complex transformations and aggregations\n",
    "    print(\"Step 2: Performing complex aggregations...\")\n",
    "    \n",
    "    # Age group analysis\n",
    "    df_with_age_groups = df.withColumn(\n",
    "        \"AgeGroup\",\n",
    "        when(col(\"Age\") < 25, \"18-24\")\n",
    "        .when(col(\"Age\") < 35, \"25-34\")\n",
    "        .when(col(\"Age\") < 45, \"35-44\")\n",
    "        .when(col(\"Age\") < 55, \"45-54\")\n",
    "        .otherwise(\"55+\")\n",
    "    )\n",
    "    \n",
    "    # Multiple complex aggregations\n",
    "    age_stats = df_with_age_groups.groupBy(\"AgeGroup\", \"State\", \"Industry\") \\\n",
    "        .agg(\n",
    "            count(\"*\").alias(\"Count\"),\n",
    "            avg(\"Salary\").alias(\"AvgSalary\"),\n",
    "            stddev(\"Salary\").alias(\"SalaryStdDev\"),\n",
    "            min(\"Salary\").alias(\"MinSalary\"),\n",
    "            max(\"Salary\").alias(\"MaxSalary\")\n",
    "        ) \\\n",
    "        .orderBy(\"AgeGroup\", \"State\", \"Industry\")\n",
    "    \n",
    "    print(\"Age group statistics by state and industry:\")\n",
    "    age_stats.show(50)\n",
    "\n",
    "    print(\"Step 3: Complex joins and window functions...\")\n",
    "    \n",
    "    # Create a second dataset for joining\n",
    "    salary_benchmarks = spark.createDataFrame([\n",
    "        (\"Tech\", 8000), (\"Finance\", 7500), (\"Healthcare\", 6500),\n",
    "        (\"Education\", 5000), (\"Retail\", 4500)\n",
    "    ], [\"Industry\", \"BenchmarkSalary\"])\n",
    "    \n",
    "    # Join with salary benchmarks\n",
    "    df_with_benchmark = df.join(salary_benchmarks, \"Industry\")\n",
    "    \n",
    "    # Window functions for ranking\n",
    "    from pyspark.sql.window import Window\n",
    "    \n",
    "    window_spec = Window.partitionBy(\"State\", \"Industry\").orderBy(desc(\"Salary\"))\n",
    "    \n",
    "    df_ranked = df_with_benchmark.withColumn(\n",
    "        \"SalaryRank\", \n",
    "        row_number().over(window_spec)\n",
    "    ).withColumn(\n",
    "        \"SalaryPercentile\",\n",
    "        percent_rank().over(window_spec)\n",
    "    ).withColumn(\n",
    "        \"SalaryVsBenchmark\",\n",
    "        round((col(\"Salary\") / col(\"BenchmarkSalary\") - 1) * 100, 2)\n",
    "    )\n",
    "    \n",
    "    # Get top performers by state\n",
    "    top_performers = df_ranked.filter(col(\"SalaryRank\") <= 10)\n",
    "    print(\"Top 10 salary performers by state and industry:\")\n",
    "    top_performers.select(\"State\", \"Industry\", \"UserID\", \"Salary\", \"SalaryVsBenchmark\").show(100)\n",
    "\n",
    "    print(\"Step 4: Complex statistical operations...\")\n",
    "    \n",
    "    # Correlation analysis (computationally expensive)\n",
    "    df_numeric = df.select(\"Age\", \"Salary\")\n",
    "    correlation = df_numeric.stat.corr(\"Age\", \"Salary\")\n",
    "    print(f\"Age-Salary Correlation: {correlation:.4f}\")\n",
    "    \n",
    "    # Cross-tabulation\n",
    "    crosstab = df.stat.crosstab(\"Gender\", \"Industry\")\n",
    "    print(\"Gender vs Industry cross-tabulation:\")\n",
    "    crosstab.show()\n",
    "\n",
    "    print(\"Step 5: Multiple data transformations...\")\n",
    "    \n",
    "    # Create multiple derived columns\n",
    "    df_enriched = df.withColumn(\"SalaryTier\", \n",
    "        when(col(\"Salary\") < 3000, \"Low\")\n",
    "        .when(col(\"Salary\") < 7000, \"Medium\")\n",
    "        .otherwise(\"High\")\n",
    "    ).withColumn(\"IsHighEarner\", col(\"Salary\") > 8000) \\\n",
    "    .withColumn(\"NormalizedAge\", (col(\"Age\") - 18) / (80 - 18)) \\\n",
    "    .withColumn(\"SalaryPerAge\", col(\"Salary\") / col(\"Age\"))\n",
    "    \n",
    "    # Final complex aggregation\n",
    "    final_summary = df_enriched.groupBy(\"State\") \\\n",
    "        .agg(\n",
    "            count(\"*\").alias(\"TotalUsers\"),\n",
    "            countDistinct(\"UserID\").alias(\"UniqueUsers\"),\n",
    "            avg(\"Salary\").alias(\"AvgSalary\"),\n",
    "            sum(when(col(\"IsHighEarner\"), 1).otherwise(0)).alias(\"HighEarners\"),\n",
    "            collect_list(\"Industry\").alias(\"Industries\")\n",
    "        )\n",
    "    \n",
    "    print(\"Final state summary:\")\n",
    "    final_summary.show(truncate=False)\n",
    "\n",
    "    # Force evaluation with an action that processes all data\n",
    "    print(\"Step 6: Final data processing...\")\n",
    "    total_records = df_enriched.count()\n",
    "    high_earner_percentage = df_enriched.filter(col(\"IsHighEarner\")).count() / total_records * 100\n",
    "    \n",
    "    end_time = time.time()\n",
    "    processing_time = end_time - start_time\n",
    "    \n",
    "    print(f\"\\nJob completed!\")\n",
    "    print(f\"Total records processed: {total_records:,}\")\n",
    "    print(f\"High earner percentage: {high_earner_percentage:.2f}%\")\n",
    "    print(f\"Processing time: {processing_time:.2f} seconds\")\n",
    "    \n",
    "    # Clean up\n",
    "    df.unpersist()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "finally:\n",
    "    time.sleep(5)  # Brief pause before cleanup\n",
    "    # Stop the Spark session\n",
    "    if 'spark' in locals():\n",
    "        spark.stop()\n",
    "        print(\"Spark session stopped\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
